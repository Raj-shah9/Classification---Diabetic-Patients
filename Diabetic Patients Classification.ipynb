{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95e405ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4014d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset\n",
    "Diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "968de8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into the dependent and the independent variables\n",
    "\n",
    "y = Diabetes['Outcome']\n",
    "\n",
    "x = Diabetes.loc[:,Diabetes.columns != 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e626a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the training and the testing datsets\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76541b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Logistic Regression classification model \n",
    "\n",
    "Classification_log = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# Fitting the training data to the Logistic regression model\n",
    "\n",
    "Classification_log.fit(x_train,y_train)\n",
    "\n",
    "# Predicting the values of the test dataset using the fitted logistic regression model\n",
    "\n",
    "y_prediction_log = Classification_log.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc1c76c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF Logistic Regression Model:  0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       123\n",
      "           1       0.66      0.64      0.65        69\n",
      "\n",
      "    accuracy                           0.75       192\n",
      "   macro avg       0.73      0.73      0.73       192\n",
      "weighted avg       0.75      0.75      0.75       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the accuracy of the logistic regression model which is 100 - MAPE (mean absolute percentage error)\n",
    "\n",
    "print(\"ACCURACY OF Logistic Regression Model: \", metrics.accuracy_score(y_test, y_prediction_log))\n",
    "\n",
    "#The classification report for the Logistic regression model\n",
    "\n",
    "class_rep_log = classification_report(y_test, y_prediction_log)\n",
    "\n",
    "print(class_rep_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "112a0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a random forest classification model \n",
    "\n",
    "Classification_model = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "\n",
    "# Fitting the training data to the classification model\n",
    "\n",
    "Classification_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "# Predicting the values of the test dataset using the fitted classification model\n",
    "\n",
    "y_prediction_rf = Classification_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d99bad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE Random Forest MODEL:  0.7395833333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80       123\n",
      "           1       0.64      0.64      0.64        69\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.72      0.72      0.72       192\n",
      "weighted avg       0.74      0.74      0.74       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the accuracy of the random forest model which is 100 - MAPE (mean absolute percentage error)\n",
    "\n",
    "print(\"ACCURACY OF THE Random Forest MODEL: \", metrics.accuracy_score(y_test, y_prediction_rf))\n",
    "\n",
    "#The classification report for the Random Forest model\n",
    "\n",
    "class_rep_rf = classification_report(y_test, y_prediction_rf)\n",
    "\n",
    "print(class_rep_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72e47c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose                     0.267336\n",
       "BMI                         0.162708\n",
       "Age                         0.141397\n",
       "DiabetesPedigreeFunction    0.118491\n",
       "BloodPressure               0.086207\n",
       "Pregnancies                 0.079908\n",
       "Insulin                     0.074315\n",
       "SkinThickness               0.069640\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importance of each independent variable used for classification.\n",
    "\n",
    "feature_imp = pd.Series(Classification_model.feature_importances_,index = x.columns).sort_values(ascending = False)\n",
    "\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262a5fd",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dd7d5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# XGBoost classification - creating a model\n",
    "\n",
    "Classification_xgb = xgb.XGBClassifier(use_label_encoder = False)\n",
    "\n",
    "\n",
    "# Fitting the XGB model using the training data\n",
    "\n",
    "Classification_xgb.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "#predicting the values of the test dataset using the xgb classification model\n",
    "\n",
    "y_pred_xgb = Classification_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4919ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF XGBoost Model:  0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80       123\n",
      "           1       0.64      0.71      0.67        69\n",
      "\n",
      "    accuracy                           0.75       192\n",
      "   macro avg       0.73      0.74      0.73       192\n",
      "weighted avg       0.76      0.75      0.75       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting the accuracy of the xgboost model which is 100 - MAPE (mean absolute percentage error)\n",
    "\n",
    "print(\"ACCURACY OF XGBoost Model: \", metrics.accuracy_score(y_test, y_pred_xgb))\n",
    "\n",
    "#The classification report for the xgboost model model\n",
    "\n",
    "class_rep_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "print(class_rep_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ecc9c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose                     0.263345\n",
       "Age                         0.141789\n",
       "BMI                         0.129308\n",
       "Insulin                     0.115281\n",
       "DiabetesPedigreeFunction    0.098113\n",
       "SkinThickness               0.091657\n",
       "BloodPressure               0.085577\n",
       "Pregnancies                 0.074930\n",
       "dtype: float32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importance of each independent variable used for XGB classification.\n",
    "\n",
    "feature_imp2 = pd.Series(Classification_xgb.feature_importances_,index = x.columns).sort_values(ascending = False)\n",
    "\n",
    "feature_imp2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
